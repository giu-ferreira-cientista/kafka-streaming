{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b54f392-0c7d-44d2-a324-aa582093284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import random\n",
    "import json\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5e583b1-07c7-4ef5-9924-5d5b8275c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Spark session & context\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local')\n",
    "         .appName('json-ml-predict-diabetes')\n",
    "         # Add kafka package\n",
    "         .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1\")\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbb14aff-42c8-4c57-a350-508b741d1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create stream dataframe setting kafka server, topic and offset option\n",
    "df = (spark\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "  .option(\"subscribe\", \"patient-data\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .option(\"group_id\", \"my-group\")   \\\n",
    "  .load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4081844-9eb6-4bf3-a614-844fd1bac123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read a small batch of data from kafka and display to the console\n",
    "\n",
    "mySchema = StructType([\n",
    " StructField(\"id\", IntegerType()),\n",
    " StructField(\"nome\", StringType()),\n",
    " StructField(\"idade\", IntegerType()),\n",
    " StructField(\"sexo\", IntegerType()),\n",
    " StructField(\"peso\", DoubleType()),\n",
    " StructField(\"altura\", IntegerType()),\n",
    " StructField(\"bpm\", DoubleType()),\n",
    " StructField(\"pressao\", DoubleType()),\n",
    " StructField(\"respiracao\", DoubleType()),\n",
    " StructField(\"temperatura\", DoubleType()),\n",
    " StructField(\"glicemia\", DoubleType()),\n",
    " StructField(\"saturacao_oxigenio\", DoubleType()),\n",
    " StructField(\"estado_atividade\", IntegerType()),\n",
    " StructField(\"dia_de_semana\", IntegerType()),\n",
    " StructField(\"periodo_do_dia\", IntegerType()),\n",
    " StructField(\"semana_do_mes\", IntegerType()),\n",
    " StructField(\"estacao_do_ano\", IntegerType()),\n",
    " StructField(\"passos\", IntegerType()),\n",
    " StructField(\"calorias\", DoubleType()),\n",
    " StructField(\"distancia\", DoubleType()),\n",
    " StructField(\"tempo\", DoubleType()),\n",
    " StructField(\"total_sleep_last_24\", DoubleType()),\n",
    " StructField(\"deep_sleep_last_24\", DoubleType()),\n",
    " StructField(\"light_sleep_last_24\", DoubleType()),\n",
    " StructField(\"awake_last_24\", DoubleType()),\n",
    " StructField(\"fumante\", IntegerType()),\n",
    " StructField(\"genetica\", IntegerType()),\n",
    " StructField(\"gestante\", IntegerType()),\n",
    " StructField(\"frutas\", IntegerType()),\n",
    " StructField(\"vegetais\", IntegerType()),\n",
    " StructField(\"alcool\", IntegerType()),\n",
    " StructField(\"doenca_coracao\", IntegerType()),     \n",
    " StructField(\"avc\", IntegerType()),\n",
    " StructField(\"colesterol_alto\", IntegerType()),   \n",
    " StructField(\"exercicio\", IntegerType()),   \n",
    " StructField(\"timestampstr\", TimestampType()),\n",
    " StructField(\"timestamp_epoch\", StringType())\n",
    " \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32c6df28-8c10-4c03-892e-472b63d0387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_json = df.selectExpr('CAST(value AS STRING) as json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dd28314-c979-4d94-b4b5-5d4817bb9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fb33880ca30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_json.select(from_json(df_json.json, mySchema).alias('raw_data')) \\\n",
    "  .select('raw_data.*') \\\n",
    "  .filter(\"nome is not NULL\") \\\n",
    "  .writeStream \\\n",
    "  .trigger(once=True) \\\n",
    "  .format(\"console\") \\\n",
    "  .start() \n",
    "  #.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a323c4c8-57a5-4e33-bdfc-f6dedf1088bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_diabetes(patient):\n",
    "\n",
    "    print(patient[0])\n",
    "\n",
    "    patient_dict = {}\n",
    "    patient_dict['id'] = patient[0]\n",
    "    patient_dict['nome'] = patient[1]\n",
    "    patient_dict['idade'] = patient[2]\n",
    "    patient_dict['sexo'] = patient[3]\n",
    "    patient_dict['peso'] = patient[4]\n",
    "    patient_dict['altura'] = patient[5]\n",
    "    patient_dict['bpm'] = patient[6]\n",
    "    patient_dict['pressao'] = patient[7]\n",
    "    patient_dict['respiracao'] = patient[8]\n",
    "    patient_dict['temperatura'] = patient[9]\n",
    "    patient_dict['glicemia'] = patient[10]\n",
    "    patient_dict['saturacao_oxigenio'] = patient[11]\n",
    "    patient_dict['estado_atividade'] = patient[12]\n",
    "    patient_dict['dia_de_semana'] = patient[13]\n",
    "    patient_dict['periodo_do_dia'] = patient[14]\n",
    "    patient_dict['semana_do_mes'] = patient[15]\n",
    "    patient_dict['estacao_do_ano'] = patient[16]\n",
    "    patient_dict['passos'] = patient[17]\n",
    "    patient_dict['calorias'] = patient[18]\n",
    "    patient_dict['distancia'] = patient[19]\n",
    "    patient_dict['tempo'] = patient[20]\n",
    "    patient_dict['total_sleep_last_24'] = patient[21]\n",
    "    patient_dict['deep_sleep_last_24'] = patient[22]\n",
    "    patient_dict['light_sleep_last_24'] = patient[23]\n",
    "    patient_dict['awake_last_24'] = patient[24]\n",
    "    patient_dict['fumante'] = patient[25]\n",
    "    patient_dict['genetica'] = patient[26]\n",
    "    patient_dict['gestante'] = patient[27]\n",
    "    patient_dict['frutas'] = patient[28]\n",
    "    patient_dict['vegetais'] = patient[29]\n",
    "    patient_dict['alcool'] = patient[30]\n",
    "    patient_dict['doenca_coracao'] = patient[31]\n",
    "    patient_dict['avc'] = patient[32]\n",
    "    patient_dict['colesterol_alto'] = patient[33]\n",
    "    patient_dict['exercicio'] = patient[34]\n",
    "    patient_dict['timestampstr'] = patient[35]\n",
    "    patient_dict['timestamp_epoch'] = patient[36]\n",
    "\n",
    "    data_jsons = json.dumps(patient_dict)\n",
    "\n",
    "    print()\n",
    "    print(data_jsons)\n",
    "    print()\n",
    "\n",
    "    result = requests.post('http://127.0.0.1:5000/predict-diabetes', json=data_jsons)\n",
    "        \n",
    "    result_json = json.dumps(result.json().replace(\"[\",\"\").replace(\"]\",\"\"))\n",
    "\n",
    "    result_json = result_json.replace('\\\\', '')[1:-1]\n",
    "    \n",
    "    #result_json = '{\"label\":1, \"score\":2.1}'\n",
    "    print()\n",
    "    print(result_json)\n",
    "    print()\n",
    "    \n",
    "    return result_json\n",
    "\n",
    "vader_udf = udf(lambda patient: predict_diabetes(patient), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8562d51-3297-422f-a4c3-de52551c899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema_output = StructType([StructField('label', IntegerType()),\\\n",
    "                            StructField('score', DoubleType())])\n",
    "\n",
    "df_json.select(from_json(df_json.json, mySchema).alias('raw_data')) \\\n",
    "  .select('raw_data.*') \\\n",
    "  .filter(\"nome is not NULL\") \\\n",
    "  .filter(\"idade is not NULL\") \\\n",
    "  .filter(\"pressao is not NULL\") \\\n",
    "  .filter(\"peso is not NULL\") \\\n",
    "  .filter(\"altura is not NULL\") \\\n",
    "  .select('nome', \\\n",
    "          from_json(vader_udf(array('*')), schema_output).alias('response'))\\\n",
    "  .select('nome', 'response.*') \\\n",
    "  .writeStream \\\n",
    "  .trigger(once=True) \\\n",
    "  .format(\"console\") \\\n",
    "  .start() \\\n",
    "  .awaitTermination()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a569fb92-275b-46f5-90e8-860cbc72f0cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "StreamingQueryException",
     "evalue": "Writing job aborted.\n=== Streaming Query ===\nIdentifier: [id = f847db55-d962-49a3-a024-a0cda5b14b0c, runId = bf478abb-eacf-469f-8ce4-eff5a9422b89]\nCurrent Committed Offsets: {KafkaV2[Subscribe[patient-data]]: {\"patient-data\":{\"0\":191}}}\nCurrent Available Offsets: {KafkaV2[Subscribe[patient-data]]: {\"patient-data\":{\"0\":201}}}\n\nCurrent State: ACTIVE\nThread State: RUNNABLE\n\nLogical Plan:\nWriteToMicroBatchDataSource org.apache.spark.sql.kafka010.KafkaStreamingWrite@52a65cee\n+- Project [cast(nome#1735 as string) AS key#1817, concat(concat(concat(concat(concat({\"label\":, cast(label#1812 as string)), ,), \"score\":), cast(score#1813 as string)), }) AS value#1818]\n   +- Project [nome#1735, response#1809.label AS label#1812, response#1809.score AS score#1813]\n      +- Project [nome#1735, from_json(StructField(label,IntegerType,true), StructField(score,DoubleType,true), <lambda>(array(cast(id#1734 as string), nome#1735, cast(idade#1736 as string), cast(sexo#1737 as string), cast(peso#1738 as string), cast(altura#1739 as string), cast(bpm#1740 as string), cast(pressao#1741 as string), cast(respiracao#1742 as string), cast(temperatura#1743 as string), cast(glicemia#1744 as string), cast(saturacao_oxigenio#1745 as string), cast(estado_atividade#1746 as string), cast(dia_de_semana#1747 as string), cast(periodo_do_dia#1748 as string), cast(semana_do_mes#1749 as string), cast(estacao_do_ano#1750 as string), cast(passos#1751 as string), cast(calorias#1752 as string), cast(distancia#1753 as string), cast(tempo#1754 as string), cast(total_sleep_last_24#1755 as string), cast(deep_sleep_last_24#1756 as string), cast(light_sleep_last_24#1757 as string), ... 13 more fields)), Some(Etc/UTC)) AS response#1809]\n         +- Filter isnotnull(altura#1739)\n            +- Filter isnotnull(peso#1738)\n               +- Filter isnotnull(pressao#1741)\n                  +- Filter isnotnull(idade#1736)\n                     +- Filter isnotnull(nome#1735)\n                        +- Project [raw_data#1732.id AS id#1734, raw_data#1732.nome AS nome#1735, raw_data#1732.idade AS idade#1736, raw_data#1732.sexo AS sexo#1737, raw_data#1732.peso AS peso#1738, raw_data#1732.altura AS altura#1739, raw_data#1732.bpm AS bpm#1740, raw_data#1732.pressao AS pressao#1741, raw_data#1732.respiracao AS respiracao#1742, raw_data#1732.temperatura AS temperatura#1743, raw_data#1732.glicemia AS glicemia#1744, raw_data#1732.saturacao_oxigenio AS saturacao_oxigenio#1745, raw_data#1732.estado_atividade AS estado_atividade#1746, raw_data#1732.dia_de_semana AS dia_de_semana#1747, raw_data#1732.periodo_do_dia AS periodo_do_dia#1748, raw_data#1732.semana_do_mes AS semana_do_mes#1749, raw_data#1732.estacao_do_ano AS estacao_do_ano#1750, raw_data#1732.passos AS passos#1751, raw_data#1732.calorias AS calorias#1752, raw_data#1732.distancia AS distancia#1753, raw_data#1732.tempo AS tempo#1754, raw_data#1732.total_sleep_last_24 AS total_sleep_last_24#1755, raw_data#1732.deep_sleep_last_24 AS deep_sleep_last_24#1756, raw_data#1732.light_sleep_last_24 AS light_sleep_last_24#1757, ... 13 more fields]\n                           +- Project [from_json(StructField(id,IntegerType,true), StructField(nome,StringType,true), StructField(idade,IntegerType,true), StructField(sexo,IntegerType,true), StructField(peso,DoubleType,true), StructField(altura,IntegerType,true), StructField(bpm,DoubleType,true), StructField(pressao,DoubleType,true), StructField(respiracao,DoubleType,true), StructField(temperatura,DoubleType,true), StructField(glicemia,DoubleType,true), StructField(saturacao_oxigenio,DoubleType,true), StructField(estado_atividade,IntegerType,true), StructField(dia_de_semana,IntegerType,true), StructField(periodo_do_dia,IntegerType,true), StructField(semana_do_mes,IntegerType,true), StructField(estacao_do_ano,IntegerType,true), StructField(passos,IntegerType,true), StructField(calorias,DoubleType,true), StructField(distancia,DoubleType,true), StructField(tempo,DoubleType,true), StructField(total_sleep_last_24,DoubleType,true), StructField(deep_sleep_last_24,DoubleType,true), StructField(light_sleep_last_24,DoubleType,true), ... 15 more fields) AS raw_data#1732]\n                              +- Project [cast(value#1002 as string) AS json#1015]\n                                 +- StreamingDataSourceV2Relation [key#1001, value#1002, topic#1003, partition#1004, offset#1005L, timestamp#1006, timestampType#1007], org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan@50c8d772, KafkaV2[Subscribe[patient-data]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStreamingQueryException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0100618c514a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw_data.*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nome is not NULL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"idade is not NULL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pressao is not NULL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStreamingQueryException\u001b[0m: Writing job aborted.\n=== Streaming Query ===\nIdentifier: [id = f847db55-d962-49a3-a024-a0cda5b14b0c, runId = bf478abb-eacf-469f-8ce4-eff5a9422b89]\nCurrent Committed Offsets: {KafkaV2[Subscribe[patient-data]]: {\"patient-data\":{\"0\":191}}}\nCurrent Available Offsets: {KafkaV2[Subscribe[patient-data]]: {\"patient-data\":{\"0\":201}}}\n\nCurrent State: ACTIVE\nThread State: RUNNABLE\n\nLogical Plan:\nWriteToMicroBatchDataSource org.apache.spark.sql.kafka010.KafkaStreamingWrite@52a65cee\n+- Project [cast(nome#1735 as string) AS key#1817, concat(concat(concat(concat(concat({\"label\":, cast(label#1812 as string)), ,), \"score\":), cast(score#1813 as string)), }) AS value#1818]\n   +- Project [nome#1735, response#1809.label AS label#1812, response#1809.score AS score#1813]\n      +- Project [nome#1735, from_json(StructField(label,IntegerType,true), StructField(score,DoubleType,true), <lambda>(array(cast(id#1734 as string), nome#1735, cast(idade#1736 as string), cast(sexo#1737 as string), cast(peso#1738 as string), cast(altura#1739 as string), cast(bpm#1740 as string), cast(pressao#1741 as string), cast(respiracao#1742 as string), cast(temperatura#1743 as string), cast(glicemia#1744 as string), cast(saturacao_oxigenio#1745 as string), cast(estado_atividade#1746 as string), cast(dia_de_semana#1747 as string), cast(periodo_do_dia#1748 as string), cast(semana_do_mes#1749 as string), cast(estacao_do_ano#1750 as string), cast(passos#1751 as string), cast(calorias#1752 as string), cast(distancia#1753 as string), cast(tempo#1754 as string), cast(total_sleep_last_24#1755 as string), cast(deep_sleep_last_24#1756 as string), cast(light_sleep_last_24#1757 as string), ... 13 more fields)), Some(Etc/UTC)) AS response#1809]\n         +- Filter isnotnull(altura#1739)\n            +- Filter isnotnull(peso#1738)\n               +- Filter isnotnull(pressao#1741)\n                  +- Filter isnotnull(idade#1736)\n                     +- Filter isnotnull(nome#1735)\n                        +- Project [raw_data#1732.id AS id#1734, raw_data#1732.nome AS nome#1735, raw_data#1732.idade AS idade#1736, raw_data#1732.sexo AS sexo#1737, raw_data#1732.peso AS peso#1738, raw_data#1732.altura AS altura#1739, raw_data#1732.bpm AS bpm#1740, raw_data#1732.pressao AS pressao#1741, raw_data#1732.respiracao AS respiracao#1742, raw_data#1732.temperatura AS temperatura#1743, raw_data#1732.glicemia AS glicemia#1744, raw_data#1732.saturacao_oxigenio AS saturacao_oxigenio#1745, raw_data#1732.estado_atividade AS estado_atividade#1746, raw_data#1732.dia_de_semana AS dia_de_semana#1747, raw_data#1732.periodo_do_dia AS periodo_do_dia#1748, raw_data#1732.semana_do_mes AS semana_do_mes#1749, raw_data#1732.estacao_do_ano AS estacao_do_ano#1750, raw_data#1732.passos AS passos#1751, raw_data#1732.calorias AS calorias#1752, raw_data#1732.distancia AS distancia#1753, raw_data#1732.tempo AS tempo#1754, raw_data#1732.total_sleep_last_24 AS total_sleep_last_24#1755, raw_data#1732.deep_sleep_last_24 AS deep_sleep_last_24#1756, raw_data#1732.light_sleep_last_24 AS light_sleep_last_24#1757, ... 13 more fields]\n                           +- Project [from_json(StructField(id,IntegerType,true), StructField(nome,StringType,true), StructField(idade,IntegerType,true), StructField(sexo,IntegerType,true), StructField(peso,DoubleType,true), StructField(altura,IntegerType,true), StructField(bpm,DoubleType,true), StructField(pressao,DoubleType,true), StructField(respiracao,DoubleType,true), StructField(temperatura,DoubleType,true), StructField(glicemia,DoubleType,true), StructField(saturacao_oxigenio,DoubleType,true), StructField(estado_atividade,IntegerType,true), StructField(dia_de_semana,IntegerType,true), StructField(periodo_do_dia,IntegerType,true), StructField(semana_do_mes,IntegerType,true), StructField(estacao_do_ano,IntegerType,true), StructField(passos,IntegerType,true), StructField(calorias,DoubleType,true), StructField(distancia,DoubleType,true), StructField(tempo,DoubleType,true), StructField(total_sleep_last_24,DoubleType,true), StructField(deep_sleep_last_24,DoubleType,true), StructField(light_sleep_last_24,DoubleType,true), ... 15 more fields) AS raw_data#1732]\n                              +- Project [cast(value#1002 as string) AS json#1015]\n                                 +- StreamingDataSourceV2Relation [key#1001, value#1002, topic#1003, partition#1004, offset#1005L, timestamp#1006, timestampType#1007], org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan@50c8d772, KafkaV2[Subscribe[patient-data]]\n"
     ]
    }
   ],
   "source": [
    "df_json.select(from_json(df_json.json, mySchema).alias('raw_data')) \\\n",
    "  .select('raw_data.*') \\\n",
    "  .filter(\"nome is not NULL\") \\\n",
    "  .filter(\"idade is not NULL\") \\\n",
    "  .filter(\"pressao is not NULL\") \\\n",
    "  .filter(\"peso is not NULL\") \\\n",
    "  .filter(\"altura is not NULL\") \\\n",
    "  .select('nome', \\\n",
    "          from_json(vader_udf(array('*')), schema_output).alias('response'))\\\n",
    "  .select('nome', 'response.*') \\\n",
    "  .select(\n",
    "      expr(\"CAST(nome AS STRING)\").alias(\"key\"),\n",
    "      expr(\"'{\\\"label\\\":' || CAST(label AS STRING) || ',' || '\\\"score\\\":' || CAST(score AS STRING) || '}'\").alias(\"value\")            \n",
    "   ) \\\n",
    "  .writeStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "  .option(\"checkpointLocation\", \"/home/jovyan/work/json/predict_diabetes\") \\\n",
    "  .option(\"topic\", \"predict-diabetes-data\")        \\\n",
    "  .start()  \\\n",
    "  .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9b612-394e-47fe-9b0a-07e542c8e1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110ae14-8adf-49d8-9033-4cbfe71aa5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
